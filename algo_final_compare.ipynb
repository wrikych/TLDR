{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from helpers import *\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data\n",
    "test_file = open('test.txt','r')\n",
    "test_text = test_file.read()\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess\n",
    "formatted_article_text, article_text = fix_it_up(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatted - no punctuation, will be used to parse words\n",
    "Article Text - with punctuation, made to create sentence list to pull from at end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word IDF\n",
    "\n",
    "word_freq, sent_list = sentence_tokenize(formatted_article_text, article_text, stop_words)\n",
    "word_idf = word_idf_create(sent_list, word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenized sentence list\n",
    "\n",
    "sent_broken = [sent_tokenize(sent) for sent in sent_list]\n",
    "sent_broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenized sentence list with words \n",
    "\n",
    "sent_cleaned = [word_tokenize(str(sent)) for sent in sent_broken]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentence IDF Vectors, Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = sent_cleaned[5]\n",
    "test2 = sent_cleaned[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(sent1, sent2, word_idf):\n",
    "        \n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    for word in sent1:\n",
    "        if word in word_idf.keys():\n",
    "            vector1[all_words.index(word)] += word_idf[word]\n",
    "    \n",
    "    for word in sent2:\n",
    "        if word in word_idf.keys():\n",
    "            vector2[all_words.index(word)] += word_idf[word]\n",
    "    \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = cosine_similarity(test1, test2, word_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Similarity Matrix - Doing this step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix= np.zeros((len(sent_cleaned), len(sent_cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sent_cleaned)):\n",
    "    for idx2 in range(len(sent_cleaned)):\n",
    "        if idx1 == idx2:\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = cosine_similarity(sent_cleaned[idx1], sent_cleaned[idx2], word_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_graph = nx.from_numpy_array(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = nx.pagerank(similarity_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sent_broken)), reverse=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_text = []\n",
    "\n",
    "for i in range(15):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['During breeding season, the pandas would return to lower altitudes to eat bamboo leaves rich in calcium.',\n",
       " 'Only a few bamboo species are widespread at the high altitudes pandas now inhabit.',\n",
       " 'The mutation time for the T1R1 gene in the giant panda is estimated to 4.2 mya while fossil evidence indicates bamboo consumption in the giant panda species at least 7 mya, signifying that although complete herbivory occurred around 2 mya, the dietary switch was initiated prior to T1R1 loss-of-function.',\n",
       " 'During the summer months, bamboo shoots rich in protein are only available at higher altitudes which causes low calcium rates in the pandas.',\n",
       " 'because of the rapid passage of large amounts of indigestible plant material through the short, straight digestive tract.',\n",
       " 'It has been estimated that an adult panda absorbs 54.8â€“66.1â€‰mg of cyanide a day through its diet.',\n",
       " 'Because of the synchronous flowering, death, and regeneration of all bamboo within a species, the giant panda must have at least two different species available in its range to avoid starvation.',\n",
       " \"Two of the panda's most distinctive features, its large size and round face, are adaptations to its bamboo diet.\",\n",
       " 'Umami taste corresponds to high levels of glutamate as found in meat and may have thus altered the food choice of the giant panda.',\n",
       " 'Genome sequencing of the giant panda suggests that the dietary switch could have initiated from the loss of the sole T1R1/T1R3 umami taste receptor, resulting from two frameshift mutations within the T1R1 exons.',\n",
       " 'Given this voluminous diet, the giant panda defecates up to 40 times a day.',\n",
       " 'Although the pseudogenisation of the umami taste receptor in Ailuropoda coincides with the dietary switch to herbivory, it is likely a result of, and not the reason for, the dietary change.',\n",
       " \"In captivity, zoos typically maintain the giant panda's bamboo diet, though some will provide specially formulated biscuits or other dietary supplements.\",\n",
       " 'The pandas would move from the valleys into the Qinling Mountains and would only return to the valleys in autumn.',\n",
       " 'This lower metabolic rate and a more sedentary lifestyle allows the giant panda to subsist on nutrient poor resources such as bamboo.\"']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56cd9e4e3bac71cab370ea6f48b0f777035e10dffe3ec952494887881b9660fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
